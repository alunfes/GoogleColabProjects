{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOaobhfO7FQPTudVEUUQpWG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alunfes/GoogleColabProjects/blob/main/GACartpole.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WXe_Bx1NZ-yv"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Agent, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, output_size),\n",
        "            nn.Softmax(dim=-1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40KYXxzjaCw4",
        "outputId": "2e369efe-e156-4edc-96e4-aab0ea265e16"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mutate(agent, mutation_rate=0.1):\n",
        "    with torch.no_grad():\n",
        "        for param in agent.parameters():\n",
        "            if len(param.shape) == 2:  # weights of linear layer\n",
        "                for i in range(param.shape[0]):\n",
        "                    for j in range(param.shape[1]):\n",
        "                        if random.random() < mutation_rate:\n",
        "                            param[i][j] += np.random.normal(0, 0.1)\n",
        "            elif len(param.shape) == 1:  # biases of linear layer\n",
        "                for i in range(param.shape[0]):\n",
        "                    if random.random() < mutation_rate:\n",
        "                        param[i] += np.random.normal(0, 0.1)\n",
        "\n",
        "def crossover(agent1, agent2):\n",
        "    child_agent = Agent(input_size, hidden_size, output_size)\n",
        "    with torch.no_grad():\n",
        "        for child_param, param1, param2 in zip(child_agent.parameters(), agent1.parameters(), agent2.parameters()):\n",
        "            child_param.data.copy_(param1.data if random.random() > 0.5 else param2.data)\n",
        "    return child_agent\n",
        "\n",
        "def evaluate_agent(agent, env, episodes=5):\n",
        "    total_reward = 0.0\n",
        "    for _ in range(episodes):\n",
        "        state = env.reset()\n",
        "        done = False\n",
        "        while not done:\n",
        "            state = torch.from_numpy(state).float().unsqueeze(0)\n",
        "            action_probabilities = agent(state)\n",
        "            action = torch.argmax(action_probabilities).item()\n",
        "            state, reward, done, _ = env.step(action)\n",
        "            total_reward += reward\n",
        "    return total_reward / episodes\n"
      ],
      "metadata": {
        "id": "j3yYe5ZoaED9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('CartPole-v1')\n",
        "input_size = env.observation_space.shape[0]\n",
        "hidden_size = 64\n",
        "output_size = env.action_space.n\n",
        "\n",
        "# 初期個体群の生成\n",
        "population_size = 50\n",
        "agents = [Agent(input_size, hidden_size, output_size) for _ in range(population_size)]\n",
        "\n",
        "# GAの繰り返し\n",
        "generations = 10\n",
        "for generation in range(generations):\n",
        "    # 評価\n",
        "    scores = [evaluate_agent(agent, env) for agent in agents]\n",
        "\n",
        "    # 選択\n",
        "    sorted_indices = np.argsort(scores)[::-1]\n",
        "    agents = [agents[i] for i in sorted_indices[:10]]  # トップ10を選択\n",
        "\n",
        "    # 交叉と突然変異\n",
        "    while len(agents) < population_size:\n",
        "        agent1, agent2 = random.sample(agents[:10], 2)\n",
        "        child = crossover(agent1, agent2)\n",
        "        mutate(child)\n",
        "        agents.append(child)\n",
        "\n",
        "    # 世代の進行を報告\n",
        "    print(f\"Generation {generation}, Top Score: {scores[sorted_indices[0]]}\")\n",
        "\n",
        "# 最適なエージェントの選択\n",
        "best_agent = agents[np.argmax([evaluate_agent(agent, env) for agent in agents])]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "id": "TVZ4aB18aFU8",
        "outputId": "093e17f1-2929-4caa-be77-c604d083bcbf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation 0, Top Score: 60.6\n",
            "Generation 1, Top Score: 77.2\n",
            "Generation 2, Top Score: 180.2\n",
            "Generation 3, Top Score: 108.6\n",
            "Generation 4, Top Score: 243.4\n",
            "Generation 5, Top Score: 490.8\n",
            "Generation 6, Top Score: 486.6\n",
            "Generation 7, Top Score: 500.0\n",
            "Generation 8, Top Score: 500.0\n",
            "Generation 9, Top Score: 500.0\n",
            "Generation 10, Top Score: 500.0\n",
            "Generation 11, Top Score: 500.0\n",
            "Generation 12, Top Score: 500.0\n",
            "Generation 13, Top Score: 500.0\n",
            "Generation 14, Top Score: 500.0\n",
            "Generation 15, Top Score: 500.0\n",
            "Generation 16, Top Score: 500.0\n",
            "Generation 17, Top Score: 500.0\n",
            "Generation 18, Top Score: 500.0\n",
            "Generation 19, Top Score: 500.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-6de2d9929aa3>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgeneration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# 評価\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mevaluate_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0magent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# 選択\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-6de2d9929aa3>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgeneration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# 評価\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mevaluate_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0magent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# 選択\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-6a39b20ef608>\u001b[0m in \u001b[0;36mevaluate_agent\u001b[0;34m(agent, env, episodes)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0maction_probabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_probabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_TnEFuixaHSM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}