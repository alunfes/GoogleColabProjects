{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOD1LR0Aomp0re11hYQPKW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alunfes/GoogleColabProjects/blob/main/Langchain_Rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vpsUuFVy-3Fi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7b41106-6222-485f-e5fc-af4a07c03cf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.13-py3-none-any.whl (810 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.29 (from langchain)\n",
            "  Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.33 (from langchain)\n",
            "  Downloading langchain_core-0.1.36-py3-none-any.whl (273 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.9/273.9 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.38-py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.33->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.13 langchain-community-0.0.29 langchain-core-0.1.36 langchain-text-splitters-0.0.1 langsmith-0.1.38 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.10.0 packaging-23.2 typing-inspect-0.9.0\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.1.1-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.1.36)\n",
            "Collecting openai<2.0.0,>=1.10.0 (from langchain-openai)\n",
            "  Downloading openai-1.14.3-py3-none-any.whl (262 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.9/262.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken<1,>=0.5.2 (from langchain-openai)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (0.1.38)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (8.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.10.0->langchain-openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.10.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2023.12.25)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.33->langchain-openai) (3.10.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain-openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.33->langchain-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.0.7)\n",
            "Installing collected packages: h11, tiktoken, httpcore, httpx, openai, langchain-openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 langchain-openai-0.1.1 openai-1.14.3 tiktoken-0.6.0\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Installing collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Chromium 123.0.6312.4 (playwright build v1105)\u001b[2m from https://playwright.azureedge.net/builds/chromium/1105/chromium-linux.zip\u001b[22m\n",
            "\u001b[1G154.7 MiB [] 0% 0.0s\u001b[0K\u001b[1G154.7 MiB [] 0% 14.9s\u001b[0K\u001b[1G154.7 MiB [] 0% 6.4s\u001b[0K\u001b[1G154.7 MiB [] 1% 4.9s\u001b[0K\u001b[1G154.7 MiB [] 1% 4.3s\u001b[0K\u001b[1G154.7 MiB [] 1% 4.0s\u001b[0K\u001b[1G154.7 MiB [] 2% 3.9s\u001b[0K\u001b[1G154.7 MiB [] 2% 4.1s\u001b[0K\u001b[1G154.7 MiB [] 2% 4.3s\u001b[0K\u001b[1G154.7 MiB [] 3% 4.4s\u001b[0K\u001b[1G154.7 MiB [] 3% 4.3s\u001b[0K\u001b[1G154.7 MiB [] 4% 4.1s\u001b[0K\u001b[1G154.7 MiB [] 4% 4.2s\u001b[0K\u001b[1G154.7 MiB [] 4% 4.5s\u001b[0K\u001b[1G154.7 MiB [] 5% 4.2s\u001b[0K\u001b[1G154.7 MiB [] 5% 4.1s\u001b[0K\u001b[1G154.7 MiB [] 6% 3.9s\u001b[0K\u001b[1G154.7 MiB [] 7% 4.1s\u001b[0K\u001b[1G154.7 MiB [] 7% 4.3s\u001b[0K\u001b[1G154.7 MiB [] 7% 4.2s\u001b[0K\u001b[1G154.7 MiB [] 8% 4.2s\u001b[0K\u001b[1G154.7 MiB [] 8% 4.3s\u001b[0K\u001b[1G154.7 MiB [] 8% 4.4s\u001b[0K\u001b[1G154.7 MiB [] 9% 4.4s\u001b[0K\u001b[1G154.7 MiB [] 9% 4.7s\u001b[0K\u001b[1G154.7 MiB [] 10% 4.6s\u001b[0K\u001b[1G154.7 MiB [] 10% 4.5s\u001b[0K\u001b[1G154.7 MiB [] 11% 4.3s\u001b[0K\u001b[1G154.7 MiB [] 11% 4.2s\u001b[0K\u001b[1G154.7 MiB [] 12% 4.2s\u001b[0K\u001b[1G154.7 MiB [] 12% 4.1s\u001b[0K\u001b[1G154.7 MiB [] 13% 4.1s\u001b[0K\u001b[1G154.7 MiB [] 13% 4.0s\u001b[0K\u001b[1G154.7 MiB [] 14% 4.0s\u001b[0K\u001b[1G154.7 MiB [] 14% 3.9s\u001b[0K\u001b[1G154.7 MiB [] 15% 3.8s\u001b[0K\u001b[1G154.7 MiB [] 16% 3.7s\u001b[0K\u001b[1G154.7 MiB [] 17% 3.6s\u001b[0K\u001b[1G154.7 MiB [] 18% 3.5s\u001b[0K\u001b[1G154.7 MiB [] 19% 3.4s\u001b[0K\u001b[1G154.7 MiB [] 20% 3.3s\u001b[0K\u001b[1G154.7 MiB [] 21% 3.2s\u001b[0K\u001b[1G154.7 MiB [] 21% 3.1s\u001b[0K\u001b[1G154.7 MiB [] 22% 3.0s\u001b[0K\u001b[1G154.7 MiB [] 23% 3.0s\u001b[0K\u001b[1G154.7 MiB [] 24% 2.9s\u001b[0K\u001b[1G154.7 MiB [] 25% 2.8s\u001b[0K\u001b[1G154.7 MiB [] 26% 2.8s\u001b[0K\u001b[1G154.7 MiB [] 26% 2.7s\u001b[0K\u001b[1G154.7 MiB [] 27% 2.7s\u001b[0K\u001b[1G154.7 MiB [] 28% 2.6s\u001b[0K\u001b[1G154.7 MiB [] 29% 2.6s\u001b[0K\u001b[1G154.7 MiB [] 30% 2.5s\u001b[0K\u001b[1G154.7 MiB [] 31% 2.4s\u001b[0K\u001b[1G154.7 MiB [] 32% 2.4s\u001b[0K\u001b[1G154.7 MiB [] 33% 2.3s\u001b[0K\u001b[1G154.7 MiB [] 34% 2.2s\u001b[0K\u001b[1G154.7 MiB [] 35% 2.2s\u001b[0K\u001b[1G154.7 MiB [] 36% 2.1s\u001b[0K\u001b[1G154.7 MiB [] 37% 2.1s\u001b[0K\u001b[1G154.7 MiB [] 37% 2.0s\u001b[0K\u001b[1G154.7 MiB [] 38% 2.0s\u001b[0K\u001b[1G154.7 MiB [] 39% 1.9s\u001b[0K\u001b[1G154.7 MiB [] 40% 1.9s\u001b[0K\u001b[1G154.7 MiB [] 41% 1.9s\u001b[0K\u001b[1G154.7 MiB [] 42% 1.8s\u001b[0K\u001b[1G154.7 MiB [] 43% 1.8s\u001b[0K\u001b[1G154.7 MiB [] 44% 1.7s\u001b[0K\u001b[1G154.7 MiB [] 45% 1.7s\u001b[0K\u001b[1G154.7 MiB [] 46% 1.6s\u001b[0K\u001b[1G154.7 MiB [] 47% 1.6s\u001b[0K\u001b[1G154.7 MiB [] 48% 1.6s\u001b[0K\u001b[1G154.7 MiB [] 48% 1.5s\u001b[0K\u001b[1G154.7 MiB [] 49% 1.5s\u001b[0K\u001b[1G154.7 MiB [] 50% 1.5s\u001b[0K\u001b[1G154.7 MiB [] 51% 1.4s\u001b[0K\u001b[1G154.7 MiB [] 52% 1.4s\u001b[0K\u001b[1G154.7 MiB [] 53% 1.4s\u001b[0K\u001b[1G154.7 MiB [] 54% 1.3s\u001b[0K\u001b[1G154.7 MiB [] 55% 1.3s\u001b[0K\u001b[1G154.7 MiB [] 56% 1.3s\u001b[0K\u001b[1G154.7 MiB [] 57% 1.2s\u001b[0K\u001b[1G154.7 MiB [] 58% 1.2s\u001b[0K\u001b[1G154.7 MiB [] 59% 1.1s\u001b[0K\u001b[1G154.7 MiB [] 60% 1.1s\u001b[0K\u001b[1G154.7 MiB [] 61% 1.1s\u001b[0K\u001b[1G154.7 MiB [] 63% 1.0s\u001b[0K\u001b[1G154.7 MiB [] 64% 1.0s\u001b[0K\u001b[1G154.7 MiB [] 65% 0.9s\u001b[0K\u001b[1G154.7 MiB [] 66% 0.9s\u001b[0K\u001b[1G154.7 MiB [] 67% 0.9s\u001b[0K\u001b[1G154.7 MiB [] 68% 0.8s\u001b[0K\u001b[1G154.7 MiB [] 69% 0.8s\u001b[0K\u001b[1G154.7 MiB [] 70% 0.8s\u001b[0K\u001b[1G154.7 MiB [] 71% 0.8s\u001b[0K\u001b[1G154.7 MiB [] 71% 0.7s\u001b[0K\u001b[1G154.7 MiB [] 73% 0.7s\u001b[0K\u001b[1G154.7 MiB [] 75% 0.6s\u001b[0K\u001b[1G154.7 MiB [] 76% 0.6s\u001b[0K\u001b[1G154.7 MiB [] 77% 0.6s\u001b[0K\u001b[1G154.7 MiB [] 78% 0.5s\u001b[0K\u001b[1G154.7 MiB [] 79% 0.5s\u001b[0K\u001b[1G154.7 MiB [] 80% 0.5s\u001b[0K\u001b[1G154.7 MiB [] 81% 0.5s\u001b[0K\u001b[1G154.7 MiB [] 82% 0.5s\u001b[0K\u001b[1G154.7 MiB [] 83% 0.4s\u001b[0K\u001b[1G154.7 MiB [] 84% 0.4s\u001b[0K\u001b[1G154.7 MiB [] 85% 0.4s\u001b[0K\u001b[1G154.7 MiB [] 86% 0.3s\u001b[0K\u001b[1G154.7 MiB [] 87% 0.3s\u001b[0K\u001b[1G154.7 MiB [] 88% 0.3s\u001b[0K\u001b[1G154.7 MiB [] 90% 0.2s\u001b[0K\u001b[1G154.7 MiB [] 91% 0.2s\u001b[0K\u001b[1G154.7 MiB [] 92% 0.2s\u001b[0K\u001b[1G154.7 MiB [] 94% 0.1s\u001b[0K\u001b[1G154.7 MiB [] 95% 0.1s\u001b[0K\u001b[1G154.7 MiB [] 96% 0.1s\u001b[0K\u001b[1G154.7 MiB [] 97% 0.0s\u001b[0K\u001b[1G154.7 MiB [] 99% 0.0s\u001b[0K\u001b[1G154.7 MiB [] 100% 0.0s\u001b[0K\n",
            "Chromium 123.0.6312.4 (playwright build v1105) downloaded to /root/.cache/ms-playwright/chromium-1105\n",
            "Downloading FFMPEG playwright build v1009\u001b[2m from https://playwright.azureedge.net/builds/ffmpeg/1009/ffmpeg-linux.zip\u001b[22m\n",
            "\u001b[1G2.6 MiB [] 0% 0.0s\u001b[0K\u001b[1G2.6 MiB [] 3% 0.4s\u001b[0K\u001b[1G2.6 MiB [] 17% 0.2s\u001b[0K\u001b[1G2.6 MiB [] 23% 0.2s\u001b[0K\u001b[1G2.6 MiB [] 36% 0.1s\u001b[0K\u001b[1G2.6 MiB [] 71% 0.0s\u001b[0K\u001b[1G2.6 MiB [] 100% 0.0s\u001b[0K\n",
            "FFMPEG playwright build v1009 downloaded to /root/.cache/ms-playwright/ffmpeg-1009\n",
            "Downloading Firefox 123.0 (playwright build v1440)\u001b[2m from https://playwright.azureedge.net/builds/firefox/1440/firefox-ubuntu-22.04.zip\u001b[22m\n",
            "\u001b[1G84.7 MiB [] 0% 0.0s\u001b[0K\u001b[1G84.7 MiB [] 0% 7.9s\u001b[0K\u001b[1G84.7 MiB [] 0% 3.3s\u001b[0K\u001b[1G84.7 MiB [] 1% 2.7s\u001b[0K\u001b[1G84.7 MiB [] 2% 2.4s\u001b[0K\u001b[1G84.7 MiB [] 3% 2.1s\u001b[0K\u001b[1G84.7 MiB [] 4% 2.0s\u001b[0K\u001b[1G84.7 MiB [] 5% 2.1s\u001b[0K\u001b[1G84.7 MiB [] 5% 2.2s\u001b[0K\u001b[1G84.7 MiB [] 7% 2.0s\u001b[0K\u001b[1G84.7 MiB [] 7% 2.1s\u001b[0K\u001b[1G84.7 MiB [] 8% 2.2s\u001b[0K\u001b[1G84.7 MiB [] 8% 2.3s\u001b[0K\u001b[1G84.7 MiB [] 8% 2.5s\u001b[0K\u001b[1G84.7 MiB [] 9% 2.5s\u001b[0K\u001b[1G84.7 MiB [] 9% 2.6s\u001b[0K\u001b[1G84.7 MiB [] 10% 2.6s\u001b[0K\u001b[1G84.7 MiB [] 11% 2.6s\u001b[0K\u001b[1G84.7 MiB [] 11% 2.7s\u001b[0K\u001b[1G84.7 MiB [] 12% 2.7s\u001b[0K\u001b[1G84.7 MiB [] 12% 2.8s\u001b[0K\u001b[1G84.7 MiB [] 13% 2.6s\u001b[0K\u001b[1G84.7 MiB [] 14% 2.5s\u001b[0K\u001b[1G84.7 MiB [] 15% 2.6s\u001b[0K\u001b[1G84.7 MiB [] 15% 2.5s\u001b[0K\u001b[1G84.7 MiB [] 16% 2.6s\u001b[0K\u001b[1G84.7 MiB [] 17% 2.6s\u001b[0K\u001b[1G84.7 MiB [] 18% 2.6s\u001b[0K\u001b[1G84.7 MiB [] 18% 2.5s\u001b[0K\u001b[1G84.7 MiB [] 19% 2.5s\u001b[0K\u001b[1G84.7 MiB [] 19% 2.6s\u001b[0K\u001b[1G84.7 MiB [] 20% 2.5s\u001b[0K\u001b[1G84.7 MiB [] 21% 2.4s\u001b[0K\u001b[1G84.7 MiB [] 22% 2.4s\u001b[0K\u001b[1G84.7 MiB [] 23% 2.3s\u001b[0K\u001b[1G84.7 MiB [] 24% 2.3s\u001b[0K\u001b[1G84.7 MiB [] 25% 2.2s\u001b[0K\u001b[1G84.7 MiB [] 26% 2.2s\u001b[0K\u001b[1G84.7 MiB [] 27% 2.2s\u001b[0K\u001b[1G84.7 MiB [] 28% 2.1s\u001b[0K\u001b[1G84.7 MiB [] 29% 2.1s\u001b[0K\u001b[1G84.7 MiB [] 30% 2.0s\u001b[0K\u001b[1G84.7 MiB [] 31% 2.0s\u001b[0K\u001b[1G84.7 MiB [] 32% 2.0s\u001b[0K\u001b[1G84.7 MiB [] 33% 1.9s\u001b[0K\u001b[1G84.7 MiB [] 34% 1.9s\u001b[0K\u001b[1G84.7 MiB [] 35% 1.8s\u001b[0K\u001b[1G84.7 MiB [] 36% 1.8s\u001b[0K\u001b[1G84.7 MiB [] 37% 1.8s\u001b[0K\u001b[1G84.7 MiB [] 38% 1.7s\u001b[0K\u001b[1G84.7 MiB [] 39% 1.7s\u001b[0K\u001b[1G84.7 MiB [] 40% 1.6s\u001b[0K\u001b[1G84.7 MiB [] 41% 1.6s\u001b[0K\u001b[1G84.7 MiB [] 42% 1.6s\u001b[0K\u001b[1G84.7 MiB [] 43% 1.5s\u001b[0K\u001b[1G84.7 MiB [] 44% 1.5s\u001b[0K\u001b[1G84.7 MiB [] 45% 1.4s\u001b[0K\u001b[1G84.7 MiB [] 46% 1.4s\u001b[0K\u001b[1G84.7 MiB [] 47% 1.4s\u001b[0K\u001b[1G84.7 MiB [] 48% 1.3s\u001b[0K\u001b[1G84.7 MiB [] 49% 1.3s\u001b[0K\u001b[1G84.7 MiB [] 50% 1.3s\u001b[0K\u001b[1G84.7 MiB [] 51% 1.3s\u001b[0K\u001b[1G84.7 MiB [] 52% 1.2s\u001b[0K\u001b[1G84.7 MiB [] 53% 1.2s\u001b[0K\u001b[1G84.7 MiB [] 54% 1.1s\u001b[0K\u001b[1G84.7 MiB [] 55% 1.1s\u001b[0K\u001b[1G84.7 MiB [] 56% 1.1s\u001b[0K\u001b[1G84.7 MiB [] 57% 1.1s\u001b[0K\u001b[1G84.7 MiB [] 58% 1.1s\u001b[0K\u001b[1G84.7 MiB [] 59% 1.0s\u001b[0K\u001b[1G84.7 MiB [] 60% 1.0s\u001b[0K\u001b[1G84.7 MiB [] 61% 1.0s\u001b[0K\u001b[1G84.7 MiB [] 62% 0.9s\u001b[0K\u001b[1G84.7 MiB [] 63% 0.9s\u001b[0K\u001b[1G84.7 MiB [] 64% 0.9s\u001b[0K\u001b[1G84.7 MiB [] 65% 0.9s\u001b[0K\u001b[1G84.7 MiB [] 65% 0.8s\u001b[0K\u001b[1G84.7 MiB [] 66% 0.8s\u001b[0K\u001b[1G84.7 MiB [] 68% 0.8s\u001b[0K\u001b[1G84.7 MiB [] 69% 0.7s\u001b[0K\u001b[1G84.7 MiB [] 70% 0.7s\u001b[0K\u001b[1G84.7 MiB [] 71% 0.7s\u001b[0K\u001b[1G84.7 MiB [] 72% 0.7s\u001b[0K\u001b[1G84.7 MiB [] 73% 0.6s\u001b[0K\u001b[1G84.7 MiB [] 74% 0.6s\u001b[0K\u001b[1G84.7 MiB [] 75% 0.6s\u001b[0K\u001b[1G84.7 MiB [] 76% 0.6s\u001b[0K\u001b[1G84.7 MiB [] 77% 0.5s\u001b[0K\u001b[1G84.7 MiB [] 78% 0.5s\u001b[0K\u001b[1G84.7 MiB [] 80% 0.5s\u001b[0K\u001b[1G84.7 MiB [] 82% 0.4s\u001b[0K\u001b[1G84.7 MiB [] 83% 0.4s\u001b[0K\u001b[1G84.7 MiB [] 85% 0.3s\u001b[0K\u001b[1G84.7 MiB [] 87% 0.3s\u001b[0K\u001b[1G84.7 MiB [] 88% 0.3s\u001b[0K\u001b[1G84.7 MiB [] 90% 0.2s\u001b[0K\u001b[1G84.7 MiB [] 92% 0.2s\u001b[0K\u001b[1G84.7 MiB [] 94% 0.1s\u001b[0K\u001b[1G84.7 MiB [] 95% 0.1s\u001b[0K\u001b[1G84.7 MiB [] 96% 0.1s\u001b[0K\u001b[1G84.7 MiB [] 97% 0.1s\u001b[0K\u001b[1G84.7 MiB [] 97% 0.0s\u001b[0K\u001b[1G84.7 MiB [] 98% 0.0s\u001b[0K\u001b[1G84.7 MiB [] 100% 0.0s\u001b[0K\n",
            "Firefox 123.0 (playwright build v1440) downloaded to /root/.cache/ms-playwright/firefox-1440\n",
            "Downloading Webkit 17.4 (playwright build v1983)\u001b[2m from https://playwright.azureedge.net/builds/webkit/1983/webkit-ubuntu-22.04.zip\u001b[22m\n",
            "\u001b[1G86.1 MiB [] 0% 0.0s\u001b[0K\u001b[1G86.1 MiB [] 0% 7.3s\u001b[0K\u001b[1G86.1 MiB [] 0% 4.4s\u001b[0K\u001b[1G86.1 MiB [] 1% 3.0s\u001b[0K\u001b[1G86.1 MiB [] 2% 2.5s\u001b[0K\u001b[1G86.1 MiB [] 3% 2.3s\u001b[0K\u001b[1G86.1 MiB [] 4% 2.2s\u001b[0K\u001b[1G86.1 MiB [] 5% 2.2s\u001b[0K\u001b[1G86.1 MiB [] 6% 2.2s\u001b[0K\u001b[1G86.1 MiB [] 7% 2.1s\u001b[0K\u001b[1G86.1 MiB [] 7% 2.2s\u001b[0K\u001b[1G86.1 MiB [] 8% 2.1s\u001b[0K\u001b[1G86.1 MiB [] 9% 2.1s\u001b[0K\u001b[1G86.1 MiB [] 9% 2.2s\u001b[0K\u001b[1G86.1 MiB [] 10% 2.2s\u001b[0K\u001b[1G86.1 MiB [] 11% 2.1s\u001b[0K\u001b[1G86.1 MiB [] 12% 2.0s\u001b[0K\u001b[1G86.1 MiB [] 12% 2.1s\u001b[0K\u001b[1G86.1 MiB [] 14% 1.9s\u001b[0K\u001b[1G86.1 MiB [] 15% 1.8s\u001b[0K\u001b[1G86.1 MiB [] 16% 1.8s\u001b[0K\u001b[1G86.1 MiB [] 17% 1.8s\u001b[0K\u001b[1G86.1 MiB [] 19% 1.7s\u001b[0K\u001b[1G86.1 MiB [] 20% 1.6s\u001b[0K\u001b[1G86.1 MiB [] 21% 1.6s\u001b[0K\u001b[1G86.1 MiB [] 22% 1.5s\u001b[0K\u001b[1G86.1 MiB [] 24% 1.5s\u001b[0K\u001b[1G86.1 MiB [] 25% 1.5s\u001b[0K\u001b[1G86.1 MiB [] 26% 1.5s\u001b[0K\u001b[1G86.1 MiB [] 26% 1.6s\u001b[0K\u001b[1G86.1 MiB [] 27% 1.6s\u001b[0K\u001b[1G86.1 MiB [] 28% 1.6s\u001b[0K\u001b[1G86.1 MiB [] 29% 1.6s\u001b[0K\u001b[1G86.1 MiB [] 30% 1.5s\u001b[0K\u001b[1G86.1 MiB [] 31% 1.5s\u001b[0K\u001b[1G86.1 MiB [] 32% 1.5s\u001b[0K\u001b[1G86.1 MiB [] 33% 1.5s\u001b[0K\u001b[1G86.1 MiB [] 34% 1.4s\u001b[0K\u001b[1G86.1 MiB [] 36% 1.4s\u001b[0K\u001b[1G86.1 MiB [] 37% 1.3s\u001b[0K\u001b[1G86.1 MiB [] 38% 1.3s\u001b[0K\u001b[1G86.1 MiB [] 39% 1.3s\u001b[0K\u001b[1G86.1 MiB [] 40% 1.2s\u001b[0K\u001b[1G86.1 MiB [] 42% 1.2s\u001b[0K\u001b[1G86.1 MiB [] 43% 1.1s\u001b[0K\u001b[1G86.1 MiB [] 45% 1.1s\u001b[0K\u001b[1G86.1 MiB [] 46% 1.1s\u001b[0K\u001b[1G86.1 MiB [] 47% 1.0s\u001b[0K\u001b[1G86.1 MiB [] 48% 1.0s\u001b[0K\u001b[1G86.1 MiB [] 49% 1.0s\u001b[0K\u001b[1G86.1 MiB [] 50% 1.0s\u001b[0K\u001b[1G86.1 MiB [] 51% 1.0s\u001b[0K\u001b[1G86.1 MiB [] 52% 1.0s\u001b[0K\u001b[1G86.1 MiB [] 53% 0.9s\u001b[0K\u001b[1G86.1 MiB [] 54% 0.9s\u001b[0K\u001b[1G86.1 MiB [] 55% 0.9s\u001b[0K\u001b[1G86.1 MiB [] 56% 0.9s\u001b[0K\u001b[1G86.1 MiB [] 57% 0.9s\u001b[0K\u001b[1G86.1 MiB [] 58% 0.9s\u001b[0K\u001b[1G86.1 MiB [] 59% 0.9s\u001b[0K\u001b[1G86.1 MiB [] 60% 0.8s\u001b[0K\u001b[1G86.1 MiB [] 61% 0.8s\u001b[0K\u001b[1G86.1 MiB [] 62% 0.8s\u001b[0K\u001b[1G86.1 MiB [] 64% 0.7s\u001b[0K\u001b[1G86.1 MiB [] 65% 0.7s\u001b[0K\u001b[1G86.1 MiB [] 66% 0.7s\u001b[0K\u001b[1G86.1 MiB [] 67% 0.7s\u001b[0K\u001b[1G86.1 MiB [] 68% 0.6s\u001b[0K\u001b[1G86.1 MiB [] 69% 0.6s\u001b[0K\u001b[1G86.1 MiB [] 70% 0.6s\u001b[0K\u001b[1G86.1 MiB [] 71% 0.6s\u001b[0K\u001b[1G86.1 MiB [] 72% 0.6s\u001b[0K\u001b[1G86.1 MiB [] 73% 0.5s\u001b[0K\u001b[1G86.1 MiB [] 74% 0.5s\u001b[0K\u001b[1G86.1 MiB [] 75% 0.5s\u001b[0K\u001b[1G86.1 MiB [] 76% 0.5s\u001b[0K\u001b[1G86.1 MiB [] 77% 0.5s\u001b[0K\u001b[1G86.1 MiB [] 78% 0.4s\u001b[0K\u001b[1G86.1 MiB [] 79% 0.4s\u001b[0K\u001b[1G86.1 MiB [] 80% 0.4s\u001b[0K\u001b[1G86.1 MiB [] 81% 0.4s\u001b[0K\u001b[1G86.1 MiB [] 82% 0.4s\u001b[0K\u001b[1G86.1 MiB [] 83% 0.3s\u001b[0K\u001b[1G86.1 MiB [] 84% 0.3s\u001b[0K\u001b[1G86.1 MiB [] 85% 0.3s\u001b[0K\u001b[1G86.1 MiB [] 86% 0.3s\u001b[0K\u001b[1G86.1 MiB [] 87% 0.3s\u001b[0K\u001b[1G86.1 MiB [] 88% 0.2s\u001b[0K\u001b[1G86.1 MiB [] 89% 0.2s\u001b[0K\u001b[1G86.1 MiB [] 90% 0.2s\u001b[0K\u001b[1G86.1 MiB [] 91% 0.2s\u001b[0K\u001b[1G86.1 MiB [] 92% 0.2s\u001b[0K\u001b[1G86.1 MiB [] 92% 0.1s\u001b[0K\u001b[1G86.1 MiB [] 94% 0.1s\u001b[0K\u001b[1G86.1 MiB [] 95% 0.1s\u001b[0K\u001b[1G86.1 MiB [] 96% 0.1s\u001b[0K\u001b[1G86.1 MiB [] 98% 0.0s\u001b[0K\u001b[1G86.1 MiB [] 99% 0.0s\u001b[0K\u001b[1G86.1 MiB [] 100% 0.0s\u001b[0K\n",
            "Webkit 17.4 (playwright build v1983) downloaded to /root/.cache/ms-playwright/webkit-1983\n",
            "Playwright Host validation warning: \n",
            "╔══════════════════════════════════════════════════════╗\n",
            "║ Host system is missing dependencies to run browsers. ║\n",
            "║ Missing libraries:                                   ║\n",
            "║     libwoff2dec.so.1.0.2                             ║\n",
            "║     libharfbuzz-icu.so.0                             ║\n",
            "║     libgstgl-1.0.so.0                                ║\n",
            "║     libgstcodecparsers-1.0.so.0                      ║\n",
            "║     libenchant-2.so.2                                ║\n",
            "║     libsecret-1.so.0                                 ║\n",
            "║     libhyphen.so.0                                   ║\n",
            "║     libmanette-0.2.so.0                              ║\n",
            "╚══════════════════════════════════════════════════════╝\n",
            "    at validateDependenciesLinux (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/server/registry/dependencies.js:216:9)\n",
            "    at async Registry._validateHostRequirements (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/server/registry/index.js:627:43)\n",
            "    at async Registry._validateHostRequirementsForExecutableIfNeeded (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/server/registry/index.js:725:7)\n",
            "    at async Registry.validateHostRequirementsForExecutablesIfNeeded (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/server/registry/index.js:714:43)\n",
            "    at async t.<anonymous> (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/cli/program.js:119:7)\n",
            "Collecting html2text\n",
            "  Downloading html2text-2024.2.26.tar.gz (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: html2text\n",
            "  Building wheel for html2text (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for html2text: filename=html2text-2024.2.26-py3-none-any.whl size=33111 sha256=3fd5621f9e3be25639450ad1e642e01dce83f92f426929e34831647eaa121d54\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/96/6d/a7eba8f80d31cbd188a2787b81514d82fc5ae6943c44777659\n",
            "Successfully built html2text\n",
            "Installing collected packages: html2text\n",
            "Successfully installed html2text-2024.2.26\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.1)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.31.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.6.4)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.25.2)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.10.0)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
            "  Downloading pulsar_client-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl (11 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.2)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.2)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.62.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.4)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.2.3)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.1)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.0)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (23.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Collecting starlette<0.37.0,>=0.36.3 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting importlib-metadata<=7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading importlib_metadata-7.0.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.24.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl (14 kB)\n",
            "Collecting opentelemetry-instrumentation==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.45b0-py3-none-any.whl (28 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl (36 kB)\n",
            "Collecting opentelemetry-util-http==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.45b0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.6)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.20.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.18.1)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (3.7.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (1.2.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=ed24e7dd35140727b1e54e4ee7d581f9edf3a2c7867f96a28053211908ab8ce8\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, mmh3, websockets, uvloop, uvicorn, python-dotenv, pulsar-client, overrides, opentelemetry-util-http, opentelemetry-semantic-conventions, opentelemetry-proto, importlib-metadata, humanfriendly, httptools, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, opentelemetry-sdk, opentelemetry-instrumentation, onnxruntime, kubernetes, fastapi, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 7.1.0\n",
            "    Uninstalling importlib_metadata-7.1.0:\n",
            "      Successfully uninstalled importlib_metadata-7.1.0\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.1.2 chroma-hnswlib-0.7.3 chromadb-0.4.24 coloredlogs-15.0.1 deprecated-1.2.14 fastapi-0.110.0 httptools-0.6.1 humanfriendly-10.0 importlib-metadata-7.0.0 kubernetes-29.0.0 mmh3-4.1.0 monotonic-1.6 onnxruntime-1.17.1 opentelemetry-api-1.24.0 opentelemetry-exporter-otlp-proto-common-1.24.0 opentelemetry-exporter-otlp-proto-grpc-1.24.0 opentelemetry-instrumentation-0.45b0 opentelemetry-instrumentation-asgi-0.45b0 opentelemetry-instrumentation-fastapi-0.45b0 opentelemetry-proto-1.24.0 opentelemetry-sdk-1.24.0 opentelemetry-semantic-conventions-0.45b0 opentelemetry-util-http-0.45b0 overrides-7.7.0 posthog-3.5.0 pulsar-client-3.4.0 pypika-0.48.9 python-dotenv-1.0.1 starlette-0.36.3 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install langchain-openai\n",
        "!pip install -U --quiet pillow==9.2.0\n",
        "!pip install -U --quiet google-search-results\n",
        "!pip install faiss-cpu\n",
        "!pip install -q langchain-openai langchain playwright beautifulsoup4\n",
        "!playwright install\n",
        "!pip install html2text\n",
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "OPENAI_API_KEY = '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'\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "mGKOmrFnXzdZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################################################################\n",
        "# Basic Invoke\n",
        "##########################################################################################\n",
        "\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "def simple_invoke(query:str) -> str:\n",
        "    model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo\")\n",
        "    parser = StrOutputParser()\n",
        "    chain = model | parser\n",
        "    return chain.invoke(query)\n",
        "\n",
        "\n",
        "simple_invoke('Can you create a table of sample company financial data ?')"
      ],
      "metadata": {
        "id": "fOben8XnZ8Vl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "56270247-aeb4-4661-8dfa-345bceff9eeb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sure! Here is a table of sample company financial data:\\n\\n| Metric           | Amount    |\\n|------------------|-----------|\\n| Revenue          | $1,000,000|\\n| Cost of Goods Sold| $500,000  |\\n| Gross Profit     | $500,000  |\\n| Operating Expenses| $300,000  |\\n| Net Income       | $200,000  |\\n| EBITDA           | $250,000  |\\n| Cash             | $100,000  |\\n| Debt             | $50,000   |\\n| Equity           | $150,000  |\\n| Earnings per Share| $2.00    |'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################################################################\n",
        "# Convert Html to text and vector similarity search\n",
        "##########################################################################################\n",
        "\n",
        "\n",
        "#https://python.langchain.com/docs/modules/data_connection/vectorstores/\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "from langchain_community.document_loaders import AsyncChromiumLoader\n",
        "from langchain_community.document_transformers import BeautifulSoupTransformer, Html2TextTransformer\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "\n",
        "def donwload_html_to_vector(url:str, query:str):\n",
        "    loader = AsyncChromiumLoader([url])\n",
        "    html = loader.load()\n",
        "    html2text = Html2TextTransformer()\n",
        "    docs_transformed = html2text.transform_documents(html)\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
        "    texts = text_splitter.split_documents(docs_transformed)\n",
        "    db = Chroma.from_documents(texts, OpenAIEmbeddings())\n",
        "    vector_query = embeddings.embed_query(query)\n",
        "    docs = db.similarity_search(query)\n",
        "    print(docs)\n",
        "    return db\n",
        "\n",
        "\n",
        "df = donwload_html_to_vector(\"https://developers.cyberagent.co.jp/blog/archives/44973/\", query = \"Faissとはどのようなものですか？\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgWD0pAA1xWw",
        "outputId": "814015c2-e194-40f8-9881-9f7a90cc9acb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content='FAISSは、大規模な高次元ベクトルのデータセットに対して高速な類似性検索を行うために設計され、', metadata={'source': 'https://developers.cyberagent.co.jp/blog/archives/44973/'}), Document(page_content='FAISSは、大規模な高次元ベクトルのデータセットに対して高速な類似性検索を行うために設計され、', metadata={'source': 'https://developers.cyberagent.co.jp/blog/archives/44973/'}), Document(page_content='FAISSは、大規模な高次元ベクトルのデータセットに対して高速な類似性検索を行うために設計され、', metadata={'source': 'https://developers.cyberagent.co.jp/blog/archives/44973/'}), Document(page_content='## Faiss\\n\\nFAISS（Facebook AI Similarity Search）は、Meta社が提供する、高性能な類似性検索ライブラリです。', metadata={'source': 'https://developers.cyberagent.co.jp/blog/archives/44973/'})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################################################################\n",
        "# Answer to question using context and template\n",
        "##########################################################################################\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "'''\n",
        "template_ = {article_topic}についての記事を書きます。\n",
        "まずはどのような記事構成にすべきか考えて下さい。\n",
        "その際には、以下の点を考慮するようにして下さい。\n",
        "想定読者：{article_readers}\n",
        "'''\n",
        "\n",
        "template = \"{subject}の{question}は何か？\"  # プロンプト（変数有り）\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"subject\", \"question\"],  # 入力変数\n",
        "    template=template,  # テンプレート\n",
        "    validate_template=True,  # 入力変数とテンプレートの検証有無\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"gpt-3.5-turbo\",  # OpenAIモデル名\n",
        "    temperature=0.7,  # 出力する単語のランダム性（0から1の範囲）\n",
        ")\n",
        "\n",
        "prompt_format = prompt_template.format(subject=\"りんご\", question=\"色\")  # LLMにPrompt Templateを指定\n",
        "response = llm(prompt_format)  # 出力\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "H-MBMtRfIFjg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "3cc9031b-378f-4411-8df8-7203a94eb35f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'content'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-614f7b1a0f60>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprompt_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt_template\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"りんご\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"色\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# LLMにPrompt Templateを指定\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_format\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 出力\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     ) -> BaseMessage:\n\u001b[0;32m--> 729\u001b[0;31m         generation = self.generate(\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         ).generations[0][0]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m                     \u001b[0mrun_managers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         flattened_outputs = [\n\u001b[1;32m    409\u001b[0m             \u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[list-item]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m                 results.append(\n\u001b[0;32m--> 397\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    398\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    587\u001b[0m                 )\n\u001b[1;32m    588\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m             result = self._generate(\n\u001b[0m\u001b[1;32m    590\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m             )\n\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgenerate_from_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m         \u001b[0mmessage_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_message_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m         params = {\n\u001b[1;32m    480\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_create_message_dicts\u001b[0;34m(self, messages, stop)\u001b[0m\n\u001b[1;32m    493\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`stop` found in both the input and default params.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stop\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         \u001b[0mmessage_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_convert_message_to_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmessage_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    493\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`stop` found in both the input and default params.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stop\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         \u001b[0mmessage_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_convert_message_to_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmessage_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_convert_message_to_dict\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \"\"\"\n\u001b[1;32m    141\u001b[0m     message_dict: Dict[str, Any] = {\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     }\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madditional_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'content'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################################\n",
        "# Simple Chain\n",
        "#######################################################\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "#llm = OpenAI(model_name=\"text-davinci-003\")\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"gpt-3.5-turbo\",  # OpenAIモデル名\n",
        "    temperature=0.7,  # 出力する単語のランダム性（0から1の範囲）\n",
        ")\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"job\"],\n",
        "    template=\"{job}に一番オススメのプログラミング言語は何?\"\n",
        ")\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "print(chain(\"データサイエンティスト\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DymdSRmYOcf7",
        "outputId": "d257dbea-8cd7-4397-fc18-65e16c777e91"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'job': 'データサイエンティスト', 'text': 'データサイエンティストにとって最もお勧めのプログラミング言語はPythonです。Pythonはデータ分析や機械学習、ディープラーニングなどの分野で幅広く使用されており、豊富なライブラリやツールが揃っています。また、構文がシンプルで読みやすく、初心者でも学習しやすい言語としても知られています。そのため、データサイエンスの初学者からプロまで幅広く利用されています。'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "f6DMAxWJbi7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "Answer the question based on the context below. If you can't\n",
        "answer the question, reply \"I don't know\".\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "prompt.format(context=\"Mary's sister is Susana\", question=\"Who is Mary's sister?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pxKUpwLZ8V2X",
        "outputId": "1f977d5e-4fd3-404c-a94a-1e58927332b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Human: \\nAnswer the question based on the context below. If you can\\'t \\nanswer the question, reply \"I don\\'t know\".\\n\\nContext: Mary\\'s sister is Susana\\n\\nQuestion: Who is Mary\\'s sister?\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | model | parser\n",
        "chain.invoke({\n",
        "    \"context\": \"Mary's sister is Susana\",\n",
        "    \"question\": \"Who is Mary's sister?\"\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_Dwq093S-aJT",
        "outputId": "47728f33-e43e-45be-96c8-d35e5418d639"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Susana'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "\n",
        "from langchain_community.document_loaders import AsyncChromiumLoader\n",
        "from langchain_community.document_transformers import BeautifulSoupTransformer, Html2TextTransformer\n",
        "\n",
        "# Load HTML\n",
        "loader = AsyncChromiumLoader([\"https://www.yahoo.co.jp\"])\n",
        "html = loader.load()\n",
        "\n",
        "html2text = Html2TextTransformer()\n",
        "docs_transformed = html2text.transform_documents(html)\n",
        "docs_transformed[0].page_content[0:500]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "R19vB9Px-dGe",
        "outputId": "48677358-f2d8-437d-fdf0-c0044cac7ab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  * Yahoo! BB\\n  * きっず版\\n  * アプリ版\\n  * ヘルプ\\n\\nホームページに設定する\\n\\n# Yahoo! JAPAN\\n\\n  * トラベル\\n\\n  * カード\\n\\n  * メール\\n\\n  * プレミアム\\n\\n  * オークション\\n\\n  * ショッピング\\n\\n# 検索\\n\\n  * ウェブ\\n  * 画像\\n  * 動画\\n  * 知恵袋\\n  * 地図\\n  * リアルタイム\\n  * 一覧\\n\\nYahoo!検索検索\\n\\nキーワード入力補助を開く\\n\\n# JavaScriptの設定について\\n\\nJavaScriptが無効になっています。すべての機能を利用するためには、有効に設定してください。  \\n詳しくは「JavaScriptの設定方法」をご覧ください。\\n\\n# お知らせ\\n\\n  * 駐車場で見かける「月極」正しくはなんて読む？\\n  * キャンドゥや松屋などPayPayクーポンでおトク\\n  * 能登地震 生活再建など情報まとめ\\n\\n# 主なサービス\\n\\n  * ショッピング\\n\\n  * オークション\\n\\n  * フリマ\\n\\n  * ZOZOTOWN\\n\\n  * LOHACO\\n\\n  * トラベル\\n\\n  * 一休.com'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from langchain.document_loaders import UnstructuredHTMLLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "\n",
        "# URLからHTMLをダウンロード\n",
        "loader = AsyncChromiumLoader([\"https://developers.cyberagent.co.jp/blog/archives/44973/\"])\n",
        "html = loader.load()\n",
        "\n",
        "# Split the text into chunks\n",
        "html2text = Html2TextTransformer()\n",
        "docs_transformed = html2text.transform_documents(html)\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
        "text_splitter.split_documents(docs_transformed)[:5]\n",
        "\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "embedded_query = embeddings.embed_query(\"Who is Mary's sister?\")\n",
        "\n",
        "\n",
        "# Create a vector store from the text chunks\n",
        "vectorstore = FAISS.from_documents(texts, model)\n",
        "\n",
        "# Create a question-answering chain\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=OpenAI(),\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vectorstore.as_retriever(),\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "# Ask a question\n",
        "question = \"What is the main topic of this HTML page?\"\n",
        "result = qa_chain(question)\n",
        "\n",
        "# Print the result\n",
        "print(result['result'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "id": "fpvUuArpEx7L",
        "outputId": "755ffd53-c723-4b56-836c-7c08ea83cebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1877, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 4156, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 15893, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 10898, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 19636, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1598, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 3350, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 5537, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2678, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1094, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1607, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 2419, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 10139, which is longer than the specified 1000\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1399, which is longer than the specified 1000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'ChatOpenAI' object has no attribute 'embed_documents'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-5d7480500a31>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Create a vector store from the text chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mvectorstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFAISS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Create a question-answering chain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/vectorstores.py\u001b[0m in \u001b[0;36mfrom_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0mmetadatas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadatas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadatas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/vectorstores/faiss.py\u001b[0m in \u001b[0;36mfrom_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    928\u001b[0m                 \u001b[0mfaiss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFAISS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m         \"\"\"\n\u001b[0;32m--> 930\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m         return cls.__from(\n\u001b[1;32m    932\u001b[0m             \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ChatOpenAI' object has no attribute 'embed_documents'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jL5kvu6EJQMr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}